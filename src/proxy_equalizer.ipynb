{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I want to be able to choose the architecture of each node independently. Maybe add a dictionary of architectures with a set default value for every node that is not in the dictionary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory Tutorial -- Proxy Equalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mlp import MLP\n",
    "from sem import SEM\n",
    "from interventions import Interventions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input the graph for the SEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to set up a structural equation model.\n",
    "It consists of a graph and the corresponding equations.\n",
    "We initialize an `SEM` object by passing in a graph as a dictionary. (Details of the data structure are in the docstring of the `SEM` class.\n",
    "\n",
    "We can then draw the graph with `sem.draw()` and print a lot of information about it with `sem.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = SEM({\"Np\": None, \"A\": None, \"Nx\": None, \"P\": [\"Np\", \"A\"], \"X\": [\"A\", \"P\", \"Nx\"], \"Y\": [\"P\", \"X\"]})\n",
    "sem.summary()\n",
    "sem.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the structural equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first check the status of the vertices to make sure we attach valid equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vertices\n",
    "print(\"All vertices: \", sem.vertices())\n",
    "# Root vertices => provide distributions\n",
    "print(\"Roots: \", sem.roots())\n",
    "# Non root vertices => provide equations making use of all parents\n",
    "print(\"Non-roots: \", sem.non_roots())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attach structural equations to the vertices with `sem.attach_equation(vertex, callable)`.\n",
    "For the root vertices, we draw from a standard normal.\n",
    "\n",
    "The only argument to the callable is an integer `n`, the number of samples to draw. Of course, we could also attach different distributions separately.\n",
    "\n",
    "**Note**: The `callable` attached to a vertex needs to return a `torch.tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in sem.roots():\n",
    "    sem.attach_equation(v, lambda n: torch.randn(n, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the non-root vertices we attach made up functions.\n",
    "\n",
    "The only argument to the callable for non-roots is a dictionary `data` that must have the vertex names as keys. This example shows how the parent vertices are accessed. We just construct a fully linear model in which all coefficients are just 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.attach_equation(\"P\", lambda data: 1 * data['Np'] + 1 * data['A'])\n",
    "sem.attach_equation(\"X\", lambda data: 1 * data['A'] + 1 * data['P'] + 1 * data['Nx'])\n",
    "sem.attach_equation(\"Y\", lambda data: 1 * data['P'] + 1 * data['X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the SEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the SEM is fully specified and we can draw samples from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sample = sem.sample(8192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `utils` module contains functions for plotting whole samples, where each variable is plotted as a function of its parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_samples(sem, orig_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the structural equations from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While in this example we provided analytical equations for the structural equation model, in reality we only get data. Our assumptions are that we guessed the causal graph correctly, but we do not know the structural equations. We assume that we have a observed samples from the graph. In this example, we will use the generated sample as our observed data.\n",
    "\n",
    "Given the graph and the observed data, we can now try to learn the structural equations. **Note**: This can be done even if we had not attached structural equations to the `SEM` object.\n",
    "\n",
    "**Arguments**: We pass in our \"observed\" sample, and can specify the number and sizes of hidden layers by `hidden_sizes` as a tuple (default: `()` i.e. no hidden layers). For single hidden layer please use `(n,)` instead of `(n)`. Moreover, we can pass a list of vertices to the `binarize` keyword to add a `torch.nn.Sigmoid()` layer at the end when predicting those vertices (default: `[]`). Further, we can pass `epochs` (default: `50`) and `batchsize` (default: `32`) as named arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.learn_from_sample(sample=orig_sample, hidden_sizes=(), binarize=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what networks have been learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For smaller networks (especially in the linear case with no hidden layers), it can be insightful to check whether the learned parameters match the actual coefficients in the analytical equations from which the sample was generated. In our simple case we get only ones, so we almost perfectly learned the linear equations (unsurprisingly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.print_learned_parameters(weights=True, biases=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the learned equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to how we sampled from the analytical structural equations before, we can now sample from the learned equations.\n",
    "\n",
    "Note, however, that we did not learn the distributions for the root vertices. Hence we have to provide values for the root vertices and can then pass those down to predict the other vertices with our learned functions with the `predict_from_sample()` function. Without further arguments, it does not mutate the input, but returns a new sample that has identical values for the root vertices and updates all non-root vertices with predictions from the learned functions.\n",
    "\n",
    "**Note**: The `predict_from_sample()` function is more flexible. One can choose manually which vertices to update (`update` argument), whether to mutate the passed in sample instead of creating a new one with `mutate=True` (then the return value is `None`) and also to use a different predictor for specified vertices by `replace={vertex: predictor}`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_sample = sem.predict_from_sample(orig_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the original sample and the learned sample simultaneously by passing a list of samples to `utils.plot_samples()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_samples(sem, [orig_sample, learned_sample], legend=['analytic', 'learned'], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fully linear case, we recover the original sample basically perfectly, i.e. we learned the structural equations exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our self made format to specify interventions. In a dict, for each proxy variable, we store another dict, which we call `functions`. In `functions`, keys are preset strings that correspond to the `known_functions` in the `Intervention` class. Current options: `'randn'`, `'rand'`, `'const'`, `'range'`, `'bernoulli'`. Every value of `functions` must be a list of tuples (!), where the tuples hold one or multiple scalar arguments (depending on the key).\n",
    "\n",
    "**Example:**\n",
    "\n",
    "This specifies five different intervened values for the proxy `'P1'` and four different intervened values for the proxy `'P2'`, a total of `5 * 4 = 20` different intervened samples.\n",
    "\n",
    "```python\n",
    "intervention_spec = {\n",
    "    'P1': {\n",
    "          'randn': [(0, 3), (0, 3), (0, 5)],\n",
    "          'const':[(1,), (0,)],\n",
    "          },\n",
    "    'P2': {\n",
    "          'range': [(-1, 1), (-5, 5)],\n",
    "          'rand':[(-1, 1), (-5, 5)],\n",
    "          },\n",
    "    }\n",
    "```\n",
    "\n",
    "Note that `Interventions` also takes a sample as an argument. Currently, interventions are done on an existing sample, i.e. first, we compute the intervened graph, given the proxies specified in the `intervention_spec`. Then we copy the sample `n_interventions` times and fill the proxy values in each sample with one of the possible combination of specified interventions. In the intervened graph, we then update all descendents of the proxies (in topological order), where we might also need values from other root vertices. This is why we already provide a sample.\n",
    "\n",
    "Strictly, this corresponds to neither counterfactuals nor interventions. As always there's no \"right\" way to this, but I'm happy for your opinions on the following options:\n",
    "\n",
    "1. Always use one single sample for the other root vertices in the intervened graph:\n",
    "    a. Use the same original sample that was used to learn the equations.\n",
    "    b. Draw a new \"base sample\" for the retraining part.\n",
    "2. For each intervened sample, draw the other root vertices in the intervened graph anew.\n",
    "\n",
    "Consider also:\n",
    "\n",
    "* In reality, we do not observe a full sample of the graph (root vertices are not observed).\n",
    "* Can we make assumptions about distribution of root vertices in real life, e.g. Gaussian? If so, how do we find the corresponding root vertex values belonging to one specific observation. (If we see P, X, Y, how do we find the corresponding Nx, A, Np?) While the distributions are enough to sample new values, the specific corresponding values are needed to learn the equations in the first step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the linear example, we choose random normal distributions with different variances as interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_spec = {\n",
    "    'P': {\n",
    "         'randn': [(0, 3), (0, 3), (0, 3)],\n",
    "         },\n",
    "    }\n",
    "interventions = Interventions(sem, orig_sample, intervention_spec)\n",
    "interventions.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a corrected version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we can actually retrain part of the target network, in this case the network for `'Y'` to minimize the variance of predictions across all different intervened samples. Note that here it seems like it only makes sense to do this for the same values of root vertices (closer to counterfactual?), because why would I want similar `'Y'` values for completely different starting values? On the other hand, we want that to be true in distribution, hence for a large batch size, we could also try to enforce that criterion with different values for the root vertices in each intervened sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = interventions.train_corrected(epochs=100, batchsize=64, biases=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the corrected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small linear models: check parameters directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this small linear network we can look directly at the parameters it has learned. We indeed see that it learns the ones everywhere originally and in the corrected version has a -1 for `'P'` instead, exactly what theory demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print(\"Original weights:\")\n",
    "sem.print_learned_parameters(show=['Y'], weights=True, biases=False)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Fair parameters:\")\n",
    "for name, param in corrected.named_parameters():\n",
    "    if 'bias' not in name:\n",
    "        print(param.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison on a new sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the full sample plots we have already encountered above for a new sample, its learned reproduction and the corrected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base, orig, fair = utils.evaluate_on_new_sample(sem, 'Y', corrected, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already seen, the learned perfectly recovers the original sample from the analytical structural equation model. The fair results coincide up to the target value `'Y'` of course, because we did not touch any other part. The dependence of `'Y'` on both `'P'` and `'X'` has been decreased, but is **not** zero (see next section for an explanation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation tools for linear prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the linear case, we can also look at (print and plot) all sorts of correlations, i.e. the slopes, r-values (Pearson Correlation Coefficient), p-values and standard errors of these tests.\n",
    "\n",
    "We see that the correlation between `'Yfair'` and `'P'` goes down as compared to `'Y'` and `'P'`, but is **not** zero. There is still correlation bettwen `'Yfair'` and `'P'` left through the confounder `'A'`. This is the main difference to all \"learning fair representation\" approaches so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_correlations(orig, sem=sem, sources=['A', 'P', 'X'], targets=['Y', 'Yfair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = sem.vertices() + ['Yfair']\n",
    "utils.plot_correlations(orig, sem=sem, sources=all_vars, targets=all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick run through a binarized example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go through the whole workflow from specifying a graph to the final evaluation (without unnecessary intermediate steps), where we binarize the value of `'P'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the graph\n",
    "sem = SEM({\"Np\": None, \"A\": None, \"Nx\": None, \"P\": [\"Np\", \"A\"], \"X\": [\"A\", \"P\", \"Nx\"], \"Y\": [\"P\", \"X\"]})\n",
    "\n",
    "# Attach equations\n",
    "for v in sem.roots():\n",
    "    sem.attach_equation(v, lambda n: torch.randn(n, 1))\n",
    "sem.attach_equation(\"P\", lambda data: (1 * data['Np'] + 1 * data['A'] > 0.0).float())\n",
    "sem.attach_equation(\"X\", lambda data: 1 * data['A'] + 5 * data['P'] + 1 * data['Nx'])\n",
    "sem.attach_equation(\"Y\", lambda data: 1 * data['P'] + 1 * data['X'])\n",
    "\n",
    "# Learn the equations (internally computes sample) and binarize the proxy P\n",
    "orig = sem.learn_from_sample(hidden_sizes=(), epochs=50, binarize=['P'])\n",
    "learned_sample = sem.predict_from_sample(orig_sample)\n",
    "\n",
    "# Specify interventions, this time 4 bernoulli interventions with p=1/2\n",
    "intervention_spec = {'P': {'bernoulli': [(0.5,), (0.5,), (0.5,), (0.5,)]}}\n",
    "interventions = Interventions(sem, orig_sample, intervention_spec)\n",
    "\n",
    "# Remove proxy discrimination\n",
    "corrected = interventions.train_corrected(epochs=100, batchsize=64, biases=False)\n",
    "                    \n",
    "# Evaluate on new sample\n",
    "base, orig, fair = utils.evaluate_on_new_sample(sem, 'Y', corrected, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this case, the predictions `Y` for `P = 1` have been drastically pushed down to closer match the predictions for `P = 0`. Since `X` was dominated by `P` (coefficient of `5` as compared to `1` for `A` and `Nx`), also the distributions of `Y` conditioned on `X` has changed drastically. The slight discrepancy of outcomes between `P = 0` and `P = 1` can be explained by the common confounding through `A`. However, I have not quantified that yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_sample = 8192\n",
    "\n",
    "# Construct the graph\n",
    "sem = SEM({\"Np\": None, \"A\": None, \"Nx\": None, \"P\": [\"Np\", \"A\"], \"X\": [\"A\", \"P\", \"Nx\"], \"Y\": [\"P\", \"X\"]})\n",
    "\n",
    "# Attach equations\n",
    "for v in sem.roots():\n",
    "    sem.attach_equation(v, lambda n: torch.randn(n, 1) * 0.1)\n",
    "sem.attach_equation(\"P\", lambda data: - 0.5 * data['Np'] + \\\n",
    "                                      0.5 * data['Np']**2 + \\\n",
    "                                      1.0 * data['A'] - \\\n",
    "                                      1.7 * data['A']**2 + \\\n",
    "                                      0.4 * data['A']**3)\n",
    "sem.attach_equation(\"X\", lambda data: 1.0 * data['A'] + \\\n",
    "                                      0.3 * data['A']**3 - \\\n",
    "                                      0.8 * data['P']**3 - \\\n",
    "                                      0.6 * data['Nx'] + \\\n",
    "                                      0.7 * data['Nx']**3)\n",
    "sem.attach_equation(\"Y\", lambda data: 0.2 * data['P'] - \\\n",
    "                                      0.6 * data['P']**2 + \\\n",
    "                                      0.5 * data['X'])\n",
    "\n",
    "# Learn the equations (internally computes sample) and binarize the proxy P\n",
    "hidden_sizes = {None: (128, 128)}\n",
    "orig_sample = sem.learn_from_sample(hidden_sizes=hidden_sizes, epochs=25, sample=n_sample, batchsize=64, weight_decay=0.0001)\n",
    "learned_sample = sem.predict_from_sample(orig_sample)\n",
    "\n",
    "# Specify interventions, this time 4 bernoulli interventions with p=1/2\n",
    "intervention_spec = {'P': {'rand': [(-1,1), (-1,1), (-1,1), (-1,1)]}}\n",
    "interventions = Interventions(sem, orig_sample, intervention_spec)\n",
    "\n",
    "# Remove proxy discrimination\n",
    "corrected = interventions.train_corrected(epochs=50, batchsize=64, biases=False, weight_decay=0.0001)\n",
    "                    \n",
    "# Evaluate on new sample\n",
    "n_sample_test = 1024\n",
    "base, orig, fair = utils.evaluate_on_new_sample(sem, 'Y', corrected, plot=True, n_sample=n_sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the same graph\n",
    "sem_fair = SEM({\"Np\": None, \"A\": None, \"Nx\": None, \"P\": [\"Np\", \"A\"], \"X\": [\"A\", \"P\", \"Nx\"], \"Y\": [\"P\", \"X\"]})\n",
    "\n",
    "# Attach fair equations\n",
    "for v in sem.roots():\n",
    "    sem_fair.attach_equation(v, lambda n: torch.randn(n, 1) * 0.1)\n",
    "sem_fair.attach_equation(\"P\", lambda data: - 0.5 * data['Np'] + \\\n",
    "                                           0.5 * data['Np']**2 + \\\n",
    "                                           1.0 * data['A'] - \\\n",
    "                                           1.7 * data['A']**2 + \\\n",
    "                                           0.4 * data['A']**3)\n",
    "sem_fair.attach_equation(\"X\", lambda data: 1.0 * data['A'] + \\\n",
    "                                           0.3 * data['A']**3 - \\\n",
    "                                           0.8 * data['P']**3 - \\\n",
    "                                           0.6 * data['Nx'] + \\\n",
    "                                           0.7 * data['Nx']**3)\n",
    "sem_fair.attach_equation(\"Y\", lambda data: 0.5 * data['X'] + \\\n",
    "                                           0.4 * data['P']**3)\n",
    "\n",
    "# Learn the equations (internally computes sample) and binarize the proxy P\n",
    "true_fair = sem_fair.sample(n_sample_test)\n",
    "\n",
    "pred_fair = sem.predict_from_sample(true_fair, update='Y', replace={'Y': corrected})\n",
    "\n",
    "utils.plot_samples(sem, [base, true_fair, pred_fair], legend=['base', 'true_fair', 'pred_fair'], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate in 3D Plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = true_fair\n",
    "s2 = pred_fair\n",
    "y1 = s1['Y'].numpy().squeeze()\n",
    "y2 = s2['Y'].numpy().squeeze()\n",
    "p1 = s1['P'].numpy().squeeze()\n",
    "p2 = s2['P'].numpy().squeeze()\n",
    "x1 = s1['X'].numpy().squeeze()\n",
    "x2 = s2['X'].numpy().squeeze()\n",
    "dat1 = np.hstack((p1[:, np.newaxis], x1[:, np.newaxis], y1[:, np.newaxis]))\n",
    "dat2 = np.hstack((p2[:, np.newaxis], x2[:, np.newaxis], y2[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter3D(p1, x1, y1, alpha=0.3)\n",
    "ax.scatter3D(p2, x2, y2, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_adult(to_drop=['fnlwgt', 'education']):\n",
    "    \"\"\"Import the relevant parts of the adult data set.\n",
    "    \n",
    "        We drop 'fnlwgt', because it is externally computed and highly predictive of the income.\n",
    "        We drop 'education', because it is redundantly encoded in 'education-num'.\n",
    "    \n",
    "    \"\"\"\n",
    "    base = '/Users/nkilbertus/ownCloud/PhD/projects/others_fairness/fairtest/data/'\n",
    "    filename = base + 'adult/adult.csv'\n",
    "    \n",
    "    print(\"Importing adult data set...\")\n",
    "    data = pd.read_csv(filename, engine='python', delimiter=\"\\s*,\\s*\", na_values=['?', ' ?', '? ', ' ? '])\n",
    "\n",
    "    if to_drop:\n",
    "        for attribute in to_drop:\n",
    "            data = data.drop(attribute, axis=1)\n",
    "\n",
    "    print(\"Data set size: \", len(data))\n",
    "    print(\"Dropped: \", to_drop)\n",
    "    print(\"Remove nan values...\", end=' ')\n",
    "    data = data.dropna()\n",
    "    print(\"DONE\")\n",
    "    print(\"New data set size: \", len(data))\n",
    "    print(\"DONE import adult data set\")\n",
    "    return data\n",
    "\n",
    "def preprocess(data, features):\n",
    "    to_one_hot = []\n",
    "    for v in features:\n",
    "        if not any([not isinstance(x, str) for x in set(data[v])]):\n",
    "            print('{}: string, categorical'.format(v))\n",
    "            pool_small_groups(data[v], inplace=True)\n",
    "            if not try_binarize(data[v]):\n",
    "                to_one_hot.append(v)\n",
    "        elif not any([int(x) != x for x in set(data[v])]):\n",
    "            print('{}: int, categorical'.format(v))\n",
    "        elif not any([float(x) != x for x in set(data[v])]):\n",
    "            print('{}: float'.format(v))\n",
    "        else:\n",
    "            raise ValueError('Could not determine type of column {}'.format(v))\n",
    "        print()\n",
    "    print(\"Encode the following columns to one-hot:\")\n",
    "    print(to_one_hot)\n",
    "    return pd.get_dummies(data, prefix=to_one_hot, columns=to_one_hot)\n",
    "            \n",
    "def pool_small_groups(data, min_examples=100, inplace=True):\n",
    "    counts = data.value_counts()\n",
    "    too_small = [k for (k, v) in counts.items() if v < min_examples]\n",
    "    \n",
    "    if len(too_small) > 1:\n",
    "        name = data.name + '_rest'\n",
    "        print(\"The following values contain fewer than {} examples and are combined into {}:\".format(min_examples, name))\n",
    "        print(too_small)\n",
    "        data.replace(too_small, name, inplace=inplace)\n",
    "\n",
    "    if not inplace:\n",
    "        return data\n",
    "\n",
    "def try_binarize(data):\n",
    "    n_values = len(set(data.values))\n",
    "    binarized = False\n",
    "    if n_values <= 2:\n",
    "        print(\"Binarize values for {} to {}\".format(data.name, list(range(n_values))))\n",
    "        data.replace(set(data.values), range(n_values), inplace=True)\n",
    "        binarized = True\n",
    "    return binarized\n",
    "\n",
    "def get_sample(data, features):\n",
    "    import torch\n",
    "    sample = {}\n",
    "    for v in features:\n",
    "        same_start = data.columns[d.columns.str.startswith(v)]\n",
    "        print(\"{} is {}-dimensional\".format(v, len(same_start)))\n",
    "        sample[v] = torch.from_numpy(d.loc[:, d.columns.str.startswith(v)].values).float()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_adult()\n",
    "features = list(data.columns)\n",
    "protected = ['race']\n",
    "use = list(set(features) - set(protected))\n",
    "print(\"All features: \", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = preprocess(data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample(d, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarize = ['Workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "\n",
    "g = {\n",
    "    'age': None,\n",
    "    'native-country': None,\n",
    "    'sex': None,\n",
    "    'race': ['native-country'],\n",
    "    'relationship': ['sex', 'education', 'age'],\n",
    "    'marital-status': ['relationship', 'sex', 'age', 'native-country', 'race'],\n",
    "    'hours-per-week': ['education', 'marital-status', 'relationship', 'native-country', 'race', 'occupation', 'Workclass'],\n",
    "    'education': ['native-country', 'race', 'sex', 'age'],\n",
    "    'occupation': ['education', 'age', 'native-country', 'race', 'marital-status', 'relationship', 'sex', 'Workclass'],\n",
    "    'Workclass': ['education', 'age', 'native-country', 'race', 'marital-status', 'relationship', 'sex'],\n",
    "    'income': ['education', 'age', 'native-country', 'race', 'marital-status', 'sex', 'Workclass', 'occupation', 'hours-per-week']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = SEM(g)\n",
    "sem.summary()\n",
    "sem.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the equations (internally computes sample) and binarize the proxy P\n",
    "hidden_sizes = {None: (256)}\n",
    "sem.learn_from_sample(sample=sample, hidden_sizes=hidden_sizes, epochs=10, batchsize=256, weight_decay=0.0001, binarize=binarize)\n",
    "learned_sample = sem.predict_from_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify interventions, this time 4 bernoulli interventions with p=1/2\n",
    "intervention_spec = {'P': {'rand': [(-1,1), (-1,1), (-1,1), (-1,1)]}}\n",
    "interventions = Interventions(sem, orig_sample, intervention_spec)\n",
    "\n",
    "# Remove proxy discrimination\n",
    "corrected = interventions.train_corrected(epochs=50, batchsize=64, biases=False, weight_decay=0.0001)\n",
    "                    \n",
    "# Evaluate on new sample\n",
    "n_sample_test = 1024\n",
    "base, orig, fair = utils.evaluate_on_new_sample(sem, 'Y', corrected, plot=True, n_sample=n_sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation tools for binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = copy.deepcopy(orig)\n",
    "s2 = copy.deepcopy(fair)\n",
    "s1['Y'] = (s1['Y'] > 0.5).float()\n",
    "s2['Y'] = (s2['Y'] > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_samples(sem, [base, s1, s2], legend=['analytical', 'learned', 'fair'], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(s1['Y'].int().numpy(), s2['Y'].int().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something with MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD?\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def median_heuristic(x):\n",
    "    d = cdist(x, x, 'sqeuclidean')\n",
    "    return 1. / np.median(d.ravel())\n",
    "\n",
    "def rbf(x1, x2, gamma=1):\n",
    "    d = cdist(x1, x2, 'sqeuclidean')\n",
    "    return np.exp(-gamma * d)\n",
    "\n",
    "def mmd(x, y, gamma=1):\n",
    "    Kxx = rbf(x, x, gamma)\n",
    "    Kyy = rbf(y, y, gamma)\n",
    "    Kxy = rbf(x, y, gamma)\n",
    "    m, n = Kxx.shape[0], Kyy.shape[0]\n",
    "    t1  = (1. / (m*(m-1))) * np.sum(Kxx - np.diag(np.diagonal(Kxx)))\n",
    "    t2  = (2. / (m*n)) * np.sum(Kxy)\n",
    "    t3  = (1. / (n*(n-1))) * np.sum(Kyy - np.diag(np.diagonal(Kyy)))\n",
    "    return t1 - t2 + t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd(dat1, dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_kernels\n",
    "from sys import stdout\n",
    "\n",
    "\n",
    "def MMD2u(K, m, n):\n",
    "    \"\"\"The MMD^2_u unbiased statistic.\n",
    "    \"\"\"\n",
    "    Kx = K[:m, :m]\n",
    "    Ky = K[m:, m:]\n",
    "    Kxy = K[:m, m:]\n",
    "    return 1.0 / (m * (m - 1.0)) * (Kx.sum() - Kx.diagonal().sum()) + \\\n",
    "        1.0 / (n * (n - 1.0)) * (Ky.sum() - Ky.diagonal().sum()) - \\\n",
    "        2.0 / (m * n) * Kxy.sum()\n",
    "\n",
    "\n",
    "def compute_null_distribution(K, m, n, iterations=10000, verbose=False,\n",
    "                              random_state=None, marker_interval=1000):\n",
    "    \"\"\"Compute the bootstrap null-distribution of MMD2u.\n",
    "    \"\"\"\n",
    "    if type(random_state) == type(np.random.RandomState()):\n",
    "        rng = random_state\n",
    "    else:\n",
    "        rng = np.random.RandomState(random_state)\n",
    "\n",
    "    mmd2u_null = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        if verbose and (i % marker_interval) == 0:\n",
    "            print(i),\n",
    "            stdout.flush()\n",
    "        idx = rng.permutation(m+n)\n",
    "        K_i = K[idx, idx[:, None]]\n",
    "        mmd2u_null[i] = MMD2u(K_i, m, n)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "\n",
    "    return mmd2u_null\n",
    "\n",
    "\n",
    "def compute_null_distribution_given_permutations(K, m, n, permutation,\n",
    "                                                 iterations=None):\n",
    "    \"\"\"Compute the bootstrap null-distribution of MMD2u given\n",
    "    predefined permutations.\n",
    "    Note:: verbosity is removed to improve speed.\n",
    "    \"\"\"\n",
    "    if iterations is None:\n",
    "        iterations = len(permutation)\n",
    "\n",
    "    mmd2u_null = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        idx = permutation[i]\n",
    "        K_i = K[idx, idx[:, None]]\n",
    "        mmd2u_null[i] = MMD2u(K_i, m, n)\n",
    "\n",
    "    return mmd2u_null\n",
    "\n",
    "\n",
    "def kernel_two_sample_test(X, Y, kernel_function='rbf', iterations=10000,\n",
    "                           verbose=False, random_state=None, **kwargs):\n",
    "    \"\"\"Compute MMD^2_u, its null distribution and the p-value of the\n",
    "    kernel two-sample test.\n",
    "    Note that extra parameters captured by **kwargs will be passed to\n",
    "    pairwise_kernels() as kernel parameters. E.g. if\n",
    "    kernel_two_sample_test(..., kernel_function='rbf', gamma=0.1),\n",
    "    then this will result in getting the kernel through\n",
    "    kernel_function(metric='rbf', gamma=0.1).\n",
    "    \"\"\"\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    XY = np.vstack([X, Y])\n",
    "    K = pairwise_kernels(XY, metric=kernel_function, **kwargs)\n",
    "    mmd2u = MMD2u(K, m, n)\n",
    "    if verbose:\n",
    "        print(\"MMD^2_u = %s\" % mmd2u)\n",
    "        print(\"Computing the null distribution.\")\n",
    "\n",
    "    mmd2u_null = compute_null_distribution(K, m, n, iterations,\n",
    "                                           verbose=verbose,\n",
    "                                           random_state=random_state)\n",
    "    p_value = max(1.0/iterations, (mmd2u_null > mmd2u).sum() /\n",
    "                  float(iterations))\n",
    "    if verbose:\n",
    "        print(\"p-value ~= %s \\t (resolution : %s)\" % (p_value, 1.0/iterations))\n",
    "\n",
    "    return mmd2u, mmd2u_null, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_two_sample_test(dat1, dat2, verbose=True, iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
