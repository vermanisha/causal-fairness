{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proxy Equalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mlp import MLP, train\n",
    "from sem import SEM\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input the graph for the SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = SEM({\"Np\": None, \"A\": None, \"Nx\": None, \"P\": [\"Np\", \"A\"], \"X\": [\"A\", \"P\", \"Nx\"], \"Y\": [\"P\", \"X\"]})\n",
    "# sem.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the structural equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the vertices are, i.e. which equations we need to attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.vertices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.attach_equation(\"Np\", lambda n: torch.randn(n, 1))\n",
    "sem.attach_equation(\"A\", lambda n: torch.randn(n, 1))\n",
    "sem.attach_equation(\"Nx\", lambda n: torch.randn(n, 1))\n",
    "sem.attach_equation(\"P\", lambda data: 1 * data['Np'] + 3 * data['A'])\n",
    "sem.attach_equation(\"X\", lambda data: 2 * data['A'] + 1 * data['P'] + 3 * data['Nx'])\n",
    "sem.attach_equation(\"Y\", lambda data: (1 * data['P'] + 3 * data['X'] > 0.0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sample = sem.sample(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_samples(sem, orig_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem.learn_from_sample(sample=orig_sample, binarize=['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_samples(sem, [orig_sample, learned_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "\n",
    "**General todos:**\n",
    "\n",
    "* Make sure order of variables in graphs/samples/stacking/networks etc. is maintained/fixed/checked somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interventions and intervened data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self made structure to specify interventions\n",
    "class Interventions:\n",
    "    \"\"\"Manage and create training data sets for interventions.\"\"\"\n",
    "    \n",
    "    # Methods for creating intervened samples\n",
    "    known_functions = {\n",
    "        'randn': (lambda self, mean, var: torch.randn(self.n_samples, 1) * var + mean),\n",
    "        'const': (lambda self, const: torch.ones(self.n_samples, 1) * const),\n",
    "        'rand': (lambda self, start, end: torch.rand(self.n_samples, 1) * (start - end) + end),\n",
    "        'range': (lambda self, start, end: torch.linspace(start, end, steps=self.n_samples).unsqueeze_(1))\n",
    "    }\n",
    "\n",
    "    def __init__(self, graph, base_sample, intervention_spec, target='Y'):\n",
    "        \"\"\"Initialize with a base sample and intervention specification.\"\"\"\n",
    "        self.base_sample = base_sample\n",
    "        self.n_samples = len(next(iter(base_sample.values())))\n",
    "        self.interventions = intervention_spec\n",
    "        self.proxies = list(intervention_spec.keys())\n",
    "        self.graph = graph\n",
    "        self.intervened_graph = self.graph.get_intervened_graph(self.proxies)\n",
    "        self.target = target\n",
    "        self._set_n_interventions()\n",
    "        self.training_samples = []\n",
    "        self._check_input()\n",
    "\n",
    "    def _check_input(self):\n",
    "        \"\"\"Some basic checks of the input.\"\"\"\n",
    "        assert self.target in self.graph.leafs(), \"Can't correct for non-leaf {}\".format(self.target)\n",
    "\n",
    "        for proxy in self.proxies:\n",
    "            assert self.target in self.graph.descendents(proxy), \"Can't correct for non-descendent {} of proxy {}.\".format(self.target, proxy)\n",
    "\n",
    "    def _set_n_interventions(self):\n",
    "        \"\"\"Compute and set the total number of interventions, i.e. training sets.\"\"\"\n",
    "        self.n_interventions = 1\n",
    "        for proxy, funcs in self.interventions.items():\n",
    "            for params in funcs.values():\n",
    "                if not isinstance(params, list):\n",
    "                    params = [params]\n",
    "                self.n_interventions *= len(params)\n",
    "\n",
    "    def get_training_samples(self):\n",
    "        \"\"\"Generate the training samples for the given interventions.\"\"\"\n",
    "        if not self.training_samples:\n",
    "            self._create_intervened_samples()\n",
    "            self._update()\n",
    "        return self.training_samples\n",
    "    \n",
    "    def _create_intervened_samples(self):\n",
    "        \"\"\"Generate copies of base sample for each intervention and set proxies.\"\"\"\n",
    "        self.training_samples = []\n",
    "        for proxy, functions in self.interventions.items():\n",
    "            for func, parameters in functions.items():\n",
    "                if not isinstance(parameters, list):\n",
    "                    parameters = [parameters]\n",
    "                for params in parameters:\n",
    "                    sample = copy.deepcopy(self.base_sample)\n",
    "                    sample[proxy] = self.known_functions[func](self, *params)\n",
    "                    self.training_samples.append(sample)\n",
    "    \n",
    "    def _update(self):\n",
    "        \"\"\"Update the variables downstream of the proxies.\"\"\"\n",
    "        downstream = list(set(sum([self.intervened_graph.descendents(proxy) for proxy in self.proxies], [])))\n",
    "        need_update = list(set(downstream).difference(set(self.target)))\n",
    "        fixed = set(self.intervened_graph.vertices()).difference(downstream)\n",
    "\n",
    "        while need_update:\n",
    "            found_one = False\n",
    "            for update in need_update:\n",
    "                if set(self.intervened_graph.parents(update)) <= set(fixed):\n",
    "                    # Found one that can be updated\n",
    "                    found_one = True\n",
    "                    # Update this variable in all samples\n",
    "                    for sample in self.training_samples:\n",
    "                        argument = Variable(combine_variables(self.intervened_graph.parents(update), sample))\n",
    "                        sample[update] = learned[update](argument).data\n",
    "                    # Remove the updated one from the list\n",
    "                    need_update.remove(update)\n",
    "            assert found_one, \"Could not update any downstream variables {} from {}\".format(need_update, fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our self made format to specify interventions.\n",
    "# In a dict, for each proxy variable, we store another dict, which we call `functions`.\n",
    "# In `functions`, keys are preset strings that correspond to the `known_functions` in the `Intervention` class.\n",
    "# Current options: 'randn', 'rand', 'const', 'range'\n",
    "# Every value of `functions` must be a list of tuples (!),\n",
    "# where the tuples hold one or multiple scalar arguments (depending on the key).\n",
    "# Example:\n",
    "# intervention_spec = {\n",
    "#     'P': {'randn': [(0, 3), (0, 3)],\n",
    "#           'const': [(1,), (0,)],\n",
    "#           'range': [(-1, 1)]\n",
    "#          },\n",
    "#     'X': {'randn': [(0, 1), (0, 1), (0, 1)]\n",
    "#          },\n",
    "#     }\n",
    "\n",
    "intervention_spec = {\n",
    "    'P': {\n",
    "#          'randn': [(0, 3), (0, 3)],\n",
    "         'const':[(1,), (0,)]\n",
    "         },\n",
    "    }\n",
    "interventions = Interventions(graph, sample, intervention_spec)\n",
    "print(\"Sample size: {}, Number of interventions {}\".format(interventions.n_samples, interventions.n_interventions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct the _real_ SEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to create/manage intervened samples differently:**\n",
    "\n",
    "* Can't have `intervention_values`, because just two different random samples should also be possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_freeze(model):\n",
    "    \"\"\"Copy a learned model and partially freeze parameters.\"\"\"\n",
    "    # Copy the original model for the target variable\n",
    "    corrected = copy.deepcopy(model)\n",
    "\n",
    "    # First freeze all parameters\n",
    "    for param in corrected.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Then only give gradients to the part that should be retrained for correction\n",
    "    # FIXME: the layer indices are hard coded. I have to find those out\n",
    "    # FIXME: not sure whether to finetune only weights or also biases?\n",
    "\n",
    "    # fine tune weights and bias:\n",
    "    for param in corrected.layers[0][0].parameters():\n",
    "        param.requires_grad = True\n",
    "    # fine tune only weights\n",
    "#     corrected.layers[0][0].weight.requires_grad = True\n",
    "\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_corrected(learned, interventions, batchsize=32, epochs=50):\n",
    "    # Some basic input checks\n",
    "    target = interventions.target\n",
    "    proxies = interventions.proxies\n",
    "    print(\"Correct for the effect of {} on {}.\".format(proxies, target))\n",
    "\n",
    "    print(\"Generate intervened samples...\", end=' ')\n",
    "    train_samples = interventions.get_training_samples()\n",
    "    print(\"DONE\")\n",
    "\n",
    "    # Sanity check\n",
    "    assert len(train_samples) == interventions.n_interventions, \"Number of interventions {} does not match number of training samples {}\".format(interventions.n_interventions, train_samples)\n",
    "    print(\"There is a total of {} interventions.\".format(len(train_samples)))    \n",
    "    \n",
    "    print(\"Freeze everything except first weights from {} to {}...\".format(proxies, target), end=' ')\n",
    "    corrected = copy_and_freeze(learned[target])\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"Set up the optimizer...\", end=' ')\n",
    "    opt = torch.optim.Adam(filter(lambda p: p.requires_grad, corrected.parameters()))\n",
    "    print(\"DONE\")\n",
    "    \n",
    "    print(\"Partially retrain the target model for correction...\", end=' ')\n",
    "    n_samples = interventions.n_samples\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        p = torch.randperm(n_samples).long()\n",
    "                    \n",
    "        for i1 in range(0, n_samples, batchsize):\n",
    "            # sample data\n",
    "            i2 = min(i1 + batchsize, n_samples)\n",
    "\n",
    "            # reset gradients\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            Ys = Variable(torch.zeros(batchsize, interventions.n_interventions))\n",
    "            for i, sample in enumerate(train_samples):\n",
    "                argument = Variable(combine_variables(interventions.intervened_graph.parents(target), sample)[i1:i2, :])\n",
    "                Ys[:, i] = corrected(argument).squeeze()\n",
    "\n",
    "            loss = torch.sum(torch.var(Ys, dim=1))\n",
    "            \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # parameter update\n",
    "            opt.step()\n",
    "    print(\"DONE\")\n",
    "    print(\"Finished correction.\")\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalizer = train_corrected(learned, interventions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(graph, target, learned, equalizer, sample):\n",
    "    \"\"\"Compare original and fair predictions.\"\"\"\n",
    "    argument = Variable(combine_variables(graph.parents(target), sample))\n",
    "    orig = learned[target](argument).data\n",
    "    fair = equalizer(argument).data\n",
    "    return orig, fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = get_sample(n_sample, eps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yorig, yfair = evaluate(graph, 'Y', learned, equalizer, test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = test_sample['P'].numpy()\n",
    "plt.plot(proxy, test_sample['Y'].numpy()-0.1, '.', proxy, yorig.numpy().round(), '.', proxy, yfair.numpy().round()+0.1, '.', alpha=0.5)\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('Y')\n",
    "plt.legend(['observed', 'original', 'fair'])\n",
    "\n",
    "feature = test_sample['X'].numpy()\n",
    "plt.figure()\n",
    "plt.plot(feature, test_sample['Y'].numpy()-0.1, '.', feature, yorig.numpy(), '.', feature, yfair.numpy()+0.1, '.', alpha=0.5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend(['observed', 'original', 'fair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(test_sample['P'].numpy(), yorig.numpy())\n",
    "print(\"Original model: intercept: {}, slope: {}\".format(model.intercept_, model.coef_))\n",
    "model = LinearRegression().fit(test_sample['P'].numpy(), yfair.numpy())\n",
    "print(\"'Fair' model: intercept: {}, slope: {}\".format(model.intercept_, model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(test_sample['X'].numpy(), yorig.numpy())\n",
    "print(\"Original model: intercept: {}, slope: {}\".format(model.intercept_, model.coef_))\n",
    "model = LinearRegression().fit(test_sample['X'].numpy(), yfair.numpy())\n",
    "print(\"'Fair' model: intercept: {}, slope: {}\".format(model.intercept_, model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathbb{R} \\to \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_linear(support=[0,1], slope=1, constant=0, n=1024, eps=0.1):\n",
    "    \"\"\"Simple linear data with noise.\"\"\"\n",
    "    x = torch.rand(n, 1) * (support[1] - support[0]) + support[0]\n",
    "    y = slope * x + constant + eps * torch.rand(n, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_quadratic(support=[0,1], a=1, b=0, c=0, n=1024, eps=0.1):\n",
    "    \"\"\"Simple linear data with noise.\"\"\"\n",
    "    x = torch.rand(n, 1) * (support[1] - support[0]) + support[0]\n",
    "    y = a * x**2 + b * x + c + eps * torch.rand(n, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = example_quadratic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.numpy(), y.numpy(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = train(MLP([1, 128, 1]), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_x = torch.linspace(-10, 10, steps=1024)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plt_x.numpy(), pred(Variable(plt_x)).data.numpy(), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathbb{R}^2 \\to \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1000, 2) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x[:, 0] * 2 - 1.5 * x[:, 1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.numpy()[:, 0], y.numpy(), '.')\n",
    "plt.plot(x.numpy()[:, 1], y.numpy(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train(MLP([2, 128, 1]), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_x = torch.randn(1000, 2) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plt_x.numpy()[:, 0], test(Variable(plt_x)).data.numpy(), '.')\n",
    "plt.plot(plt_x.numpy()[:, 1], test(Variable(plt_x)).data.numpy(), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOPMENTAL STAGE -- DEPRECATED BEYOND THIS POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import copy\n",
    "import tqdm\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from mlp import MLP, train\n",
    "from graph import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal multilayer perceptron + training (now in `mlp.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"A simple fully connected feed forward network.\"\"\"\n",
    "    def __init__(self, sizes, final=None):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "        \n",
    "        A variable size network with only fully connected layers and ELU activations after all but the last layer.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        sizes: A list of the numbers of neurons in the layers.\n",
    "               len(sizes)-1 is the number of layers.\n",
    "               First and last entries are input and output dimension.\n",
    "        final: What to use as a final layer, e.g. torch.nn.Sigmoid()\n",
    "               None (default) means no final layer (regression vs. classification).\n",
    "               \n",
    "        Example:\n",
    "            A network with 2-dimensional input, one hidden layer with 128 neurons and 1-dimensional output for regression.\n",
    "            >>> net = MLP([2, 128, 1])\n",
    "            \n",
    "            A network with 10-dimensional input, two hidden layers of 128 and 256 neurons and 1-dimensional output for classification.\n",
    "            >>> net = MLP([10, 128, 256, 1], final=torch.nn.Sigmoid())            \n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        # If there is only one input dimension, everything is fine\n",
    "        if sizes[0] == 1:\n",
    "            self.layers.append(nn.Linear(sizes[0], sizes[1]))\n",
    "        # For multiple input dimensions, each one has a separate following hidden layer.\n",
    "        # This is necessary for the partial training later on.\n",
    "        else:\n",
    "            self.layers.append(nn.ModuleList([nn.Linear(1, sizes[1]) for _ in range(sizes[0])]))\n",
    "            \n",
    "        # Add the remaining layers with elu activations\n",
    "        for i in range(len(sizes) - 1)[1:]:\n",
    "            if i != (len(sizes) - 1):\n",
    "                self.layers.append(nn.ELU()) \n",
    "            self.layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            \n",
    "        if final is not None:\n",
    "            self.layers.append(final)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward pass.\"\"\"\n",
    "        # If there are multiple inputs, add up their hidden layers\n",
    "        if isinstance(self.layers[0], collections.Iterable):\n",
    "            y = self.layers[0][0](x[:, 0, None])\n",
    "            for i in range(1, len(self.layers[0])):\n",
    "                y += self.layers[0][i](x[:, i, None])\n",
    "            return nn.Sequential(*[self.layers[i] for i in range(1, len(self.layers))])(y)\n",
    "        # Otherwise just build a simple sequential model\n",
    "        else:\n",
    "            return nn.Sequential(*self.layers)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, x, y, loss_func=nn.MSELoss(), epochs=50, batchsize=32):\n",
    "    \"\"\"\n",
    "    Train a network.\n",
    "    \n",
    "    Args:\n",
    "        net:       A network module.\n",
    "        x:         Training input data.\n",
    "        y:         Training labels.\n",
    "        loos_func: Loss function, default is nn.MSELoss(), i.e. mean squared error.\n",
    "        n_epochs:  Number of training epochs.\n",
    "    \"\"\"\n",
    "    opt = torch.optim.Adam(net.parameters())\n",
    "    n_samples = x.size(0)\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle training data\n",
    "        p = torch.randperm(n_samples).long()\n",
    "        xp = x[p]\n",
    "        yp = y[p]\n",
    "\n",
    "        for i1 in range(0, n_samples, batchsize):\n",
    "            # Extract a batch\n",
    "            i2 = min(i1 + batchsize, n_samples)\n",
    "            xi, yi = xp[i1:i2], yp[i1:i2]\n",
    "\n",
    "            # Reset gradients\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            loss = loss_func(net(Variable(xi)), Variable(yi))\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Parameter update\n",
    "            opt.step()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The graph representation (now in `graph.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \"\"\"A light weight, self made graph representation.\"\"\"\n",
    "    def __init__(self, graph):\n",
    "        \"\"\"Initialize a Graph object.\"\"\"\n",
    "        if isinstance(graph, dict):\n",
    "            self.graph = graph\n",
    "        else:\n",
    "            print(\"Could not process input {} as graph. Initialized empty graph.\".format(graph))\n",
    "            self.graph = None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Define representation.\"\"\"\n",
    "        import pprint\n",
    "        return pprint.pformat(self.graph)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Define string format.\"\"\"\n",
    "        import pprint\n",
    "        return pprint.pformat(self.graph)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.graph)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.graph[item]\n",
    "    \n",
    "    def _try_add_vertex(self, vertex):\n",
    "        if vertex in self.graph:\n",
    "            print(\"Vertex already exists.\")\n",
    "        else:\n",
    "            self.graph[vertex] = None\n",
    "            print(\"Added vertex \", vertex)\n",
    "    \n",
    "    def _try_add_edge(self, source, target):\n",
    "        if source in self.graph:\n",
    "            if target not in self.graph[source]:\n",
    "                self.graph[source].append(target)\n",
    "            else:\n",
    "                print(\"Edge already exists.\")\n",
    "        else:\n",
    "            self.graph[source] = [target]\n",
    "    \n",
    "    def add_vertices(self, vertices):\n",
    "        \"\"\"Add one or multiple vertices to the graph.\"\"\"\n",
    "        if isinstance(vertices, collections.Iterable):\n",
    "            for v in vertices:\n",
    "                _try_add_vertex(v)\n",
    "        else:\n",
    "            _try_add_vertex(v)\n",
    "\n",
    "    def add_edge(self, source, target):\n",
    "        \"\"\"Add a single edge from source to target.\"\"\"\n",
    "        self._try_add_edge(source, target)\n",
    "        \n",
    "    def vertices(self):\n",
    "        \"\"\"Find all vertices.\"\"\"\n",
    "        return list(self.graph.keys())\n",
    "    \n",
    "    def edges(self):\n",
    "        \"\"\"Find all edges.\"\"\"\n",
    "        edges = []\n",
    "        for node, parents in self.graph.items():\n",
    "            if parents is not None:\n",
    "                for p in parents:\n",
    "                    edges.append({p: node})\n",
    "        return edges\n",
    "\n",
    "    def roots(self):\n",
    "        \"\"\"Find all root vertices.\"\"\"\n",
    "        return [node for node in self.graph if self.graph[node] is None]\n",
    "\n",
    "    def non_roots(self):\n",
    "        return [node for node in self.graph if self.graph[node] is not None]\n",
    "    \n",
    "    def leafs(self):\n",
    "        \"\"\"Find all leaf vertices.\"\"\"\n",
    "        return list(set(self.vertices()).difference(self.non_leafs()))\n",
    "\n",
    "    def non_leafs(self):\n",
    "        \"\"\"Find all non-leaf vertices.\"\"\"\n",
    "        return list(set(sum([p for p in self.graph.values() if p is not None], [])))\n",
    "    \n",
    "    def parents(self, vertex):\n",
    "        \"\"\"Find the parents of a vertex.\"\"\"\n",
    "        return self.graph[vertex]\n",
    "\n",
    "    def children(self, vertex):\n",
    "        \"\"\"Find the children of a vertex.\"\"\"\n",
    "        children = []\n",
    "        for node, parents in self.graph.items():\n",
    "            if parents is not None and vertex in parents:\n",
    "                children.append(node)\n",
    "        return children\n",
    "    \n",
    "    def descendents(self, vertex):\n",
    "        \"\"\"Find all descendents of a vertex.\"\"\"\n",
    "        descendents = []\n",
    "        current_children = self.children(vertex)\n",
    "        if not current_children:\n",
    "            return descendents\n",
    "    \n",
    "        descendents += current_children\n",
    "    \n",
    "        for child in current_children:\n",
    "            new_descendents = self.descendents(child)\n",
    "            descendents += new_descendents\n",
    "\n",
    "        return list(set(descendents))\n",
    "    \n",
    "    def get_intervened_graph(self, interventions):\n",
    "        \"\"\"Return the intervened graph as a new graph.\"\"\"\n",
    "        intervened_graph = copy.deepcopy(self.graph)\n",
    "        if isinstance(interventions, collections.Iterable):\n",
    "            for i in interventions:\n",
    "                intervened_graph[i] = None\n",
    "        else:\n",
    "            intervened_graph[interventions] = None\n",
    "        return Graph(intervened_graph)\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"Print summary of the graph.\"\"\"\n",
    "        print(\"Vertices in graph\", self.vertices())\n",
    "        print(\"Roots in graph\", self.roots())\n",
    "        print(\"Non-roots in graph\", self.non_roots())\n",
    "        print(\"Leafs in graph\", self.leafs())\n",
    "        print(\"Non-leafs in graph\", self.non_leafs())\n",
    "        print(\"Edges in the graph\", self.edges())\n",
    "\n",
    "        for v in self.vertices():\n",
    "            print(\"Children of {} are {}\".format(v, self.children(v)))\n",
    "            print(\"Parents of {} are {}\".format(v, self.parents(v)))\n",
    "            print(\"Descendents of {} are {}\".format(v, self.descendents(v)))\n",
    "        \n",
    "    def _convert_to_nx(self):\n",
    "        import networkx as nx\n",
    "        G = nx.DiGraph()\n",
    "        for edge in self.edges():\n",
    "            edge = next(iter(edge.items()))\n",
    "            G.add_edge(*edge)\n",
    "        return G\n",
    "\n",
    "    def topological_sort(self):\n",
    "        import networkx as nx\n",
    "        G = self._convert_to_nx()\n",
    "        return list(nx.topological_sort(G))\n",
    "    \n",
    "    def draw(self):\n",
    "        import networkx as nx\n",
    "#         from nxpd import draw, nxpdParams\n",
    "#         nxpdParams['show'] = 'ipynb'\n",
    "        G = self._convert_to_nx()\n",
    "        G.graph['dpi'] = 150\n",
    "        draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling (now merged with graph in graph superclass `sem.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we define a causal graph\n",
    "# Nodes are the keys of the graph and the values are the parents(!) of the key.\n",
    "# Setting the value to None means that the node is a root of the graph.\n",
    "graph = Graph({\"Np\": None, \"A\": None, \"Nx\": None, \"P\": [\"Np\", \"A\"], \"X\": [\"A\", \"P\", \"Nx\"], \"Y\": [\"P\", \"X\"]})\n",
    "graph.summary()\n",
    "graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default number of examples in a sample\n",
    "n_sample = 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely hard coded sampling from one given graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(n, eps=0.05):\n",
    "    \"\"\"Generate sample data specific to a graph (hand tuned).\"\"\"\n",
    "    # Randomly sample the root nodes variables\n",
    "    Np = torch.randn(n, 1)\n",
    "    Nx = torch.randn(n, 1)\n",
    "#     A = torch.zeros(n, 1)\n",
    "#     A[torch.randperm(n).long()[:int(n/2)]] = 1.\n",
    "    A = torch.randn(n, 1)\n",
    "    \n",
    "    P = 1 * Np + 3 * A + eps * torch.randn(n, 1)\n",
    "#     P = (1 * Np + 3 * A + eps * torch.randn(n, 1) > 0.0).float()\n",
    "    X = 2 * A + 1 * P + 3 * Nx + eps * torch.randn(n, 1)\n",
    "#     Y = 1 * P + 3 * X + eps * torch.randn(n, 1)\n",
    "    Y = (1 * P + 3 * X + eps * torch.randn(n, 1) > 0.0).float()\n",
    "    return dict(Np=Np, Nx=Nx, A=A, P=P, X=X, Y=Y)\n",
    "\n",
    "def plot_samples(graph, samples):\n",
    "    \"\"\"Plot all relevant dependencies in a graph from a/multiple sample(s).\"\"\"        \n",
    "    # If we did not already receive a list of samples, make one element list\n",
    "    if not isinstance(samples, list):\n",
    "        samples = [samples]\n",
    "    # Get non root variables\n",
    "    non_roots = graph.non_roots()\n",
    "    # Get maximum number of input variables\n",
    "    max_deps = max([len(graph.parents(var)) for var in non_roots])\n",
    "    \n",
    "    fig, axs = plt.subplots(len(non_roots), max_deps, figsize=(5 * max_deps, 5 * len(non_roots)))\n",
    "\n",
    "    # Go through all dependencies and plot them as 2D scatter plots\n",
    "    for i, y_var in enumerate(non_roots):\n",
    "        for j, x_var in enumerate(graph.parents(y_var)):\n",
    "            for sample in samples:\n",
    "                axs[i, j].plot(sample[x_var].numpy(), sample[y_var].numpy(), '.')\n",
    "                axs[i, j].set_xlabel(x_var)\n",
    "                axs[i, j].set_ylabel(y_var)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Pure util function\n",
    "def combine_variables(variables, sample):\n",
    "    \"\"\"Stack variables from sample along new axis.\"\"\"\n",
    "    data = torch.stack([sample[i] for i in variables], dim=1).squeeze()\n",
    "    if len(data.size()) == 1:\n",
    "        data.unsqueeze_(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample should probably come as a pandas dataframe?\n",
    "# But then the things are not torch arrays, so maybe keeping it as a dict is smarter?\n",
    "sample = get_sample(n_sample, eps=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the _real_ SEM (now also part of `sem.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_sem(graph, sample, hidden_sizes=(), binarize=None):\n",
    "    \"\"\"Given a graph and a sample from it, learn the structural equations.\"\"\"\n",
    "    learned = {}\n",
    "    for vertex in graph.non_roots():\n",
    "        print(\"Training {} -> {}...\".format(graph.parents(vertex), vertex), end=' ')\n",
    "        data = combine_variables(graph.parents(vertex), sample)\n",
    "        if vertex in binarize:\n",
    "            final = nn.Sigmoid()\n",
    "        else:\n",
    "            final = None\n",
    "        learned[vertex] = train(MLP([data.size(-1), *hidden_sizes, 1], final=final), data, sample[vertex])\n",
    "        print(\"DONE\")\n",
    "    return learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(graph, sample, learned):\n",
    "    new_sample = copy.deepcopy(sample)\n",
    "    need_update = [v for v in graph.topological_sort() if v not in graph.roots()]\n",
    "    print(\"Updating the nodes {}...\".format(need_update), end=' ')\n",
    "    for update in need_update:\n",
    "        argument = Variable(combine_variables(graph.parents(update), new_sample))\n",
    "        new_sample[update] = learned[update](argument).data\n",
    "    print(\"DONE\")\n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_from_sample(self, sample, learned):\n",
    "        from torch.autograd import Variable\n",
    "        new_sample = copy.deepcopy(sample)\n",
    "        need_update = [v for v in self.topological_sort()\n",
    "                       if v not in self.roots()]\n",
    "        print(\"Updating the nodes {}.\".format(need_update))\n",
    "        for update in need_update:\n",
    "            print(\"Updating node {}...\".format(update), end=' ')\n",
    "            argument = Variable(utils.combine_variables(self.parents(update),\n",
    "                                                        new_sample))\n",
    "            new_sample[update] = learned[update](argument).data\n",
    "        print(\"DONE\")\n",
    "        return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned = learn_sem(graph, sample, binarize='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sample = predict_sample(graph, sample, learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(graph, [sample, pred_sample])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
